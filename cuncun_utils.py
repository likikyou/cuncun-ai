import os
import json
import time
import requests
import logging
import hashlib
import hmac
import re
import base64
import shutil
import chromadb
from openai import OpenAI
from datetime import datetime, timedelta
from pythonjsonlogger import jsonlogger  #
from config import Config
from Crypto.Cipher import AES

# --- 1. åˆå§‹åŒ–ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ ---

class CustomJsonFormatter(jsonlogger.JsonFormatter):
    def add_fields(self, log_record, created, message):
        super().add_fields(log_record, created, message)
        log_record['timestamp'] = datetime.now().isoformat()
        # ä¿®æ­£ï¼šç›´æ¥è·å–æ ‡å‡† levelnameï¼Œå¦‚æœä¸å­˜åœ¨åˆ™é»˜è®¤ä¸º INFO
        log_record['level'] = log_record.get('levelname', 'INFO')
        log_record['service'] = 'feishu-cuncun-pro'

def setup_logging():
    os.makedirs(os.path.dirname(Config.LOG_FILE), exist_ok=True)
    
    # æ–‡ä»¶å¤„ç†å™¨ (æŒä¹…åŒ–å­˜å‚¨)
    file_handler = logging.FileHandler(Config.LOG_FILE, encoding='utf-8')
    # å±å¹•å¤„ç†å™¨ (ç”¨äº pm2 logs æŸ¥çœ‹)
    stream_handler = logging.StreamHandler()
    
    # åº”ç”¨ JSON æ ¼å¼åŒ–
    formatter = CustomJsonFormatter('%(timestamp)s %(level)s %(name)s %(message)s')
    file_handler.setFormatter(formatter)
    stream_handler.setFormatter(formatter)
    
    _logger = logging.getLogger("feishu-utils")
    _logger.handlers = []  # æ¸…ç©ºæ—§å¤„ç†å™¨ï¼Œé˜²æ­¢é‡å¤æ‰“å°
    _logger.addHandler(file_handler)
    _logger.addHandler(stream_handler)
    _logger.setLevel(logging.INFO)
    return _logger

logger = setup_logging()

# --- é£ä¹¦ç­¾åæ ¡éªŒï¼šé˜²æ­¢éæ³•æ¶ˆè€— API é¢åº¦ ---
import hashlib
# import hmac  <-- è¿™ä¸€è¡Œå¯ä»¥åˆ æ‰æˆ–æ³¨é‡Šæ‰

import hashlib

def verify_signature(request_headers, request_body):
    """
    ğŸ›¡ï¸ é£ä¹¦ç­¾åæ ¡éªŒ (å…¼å®¹æ¨¡å¼)
    å¦‚æœæ²¡æœ‰é…ç½® FEISHU_ENCRYPT_KEYï¼Œåˆ™ç›´æ¥æ”¾è¡Œï¼Œæ–¹ä¾¿è°ƒè¯•ã€‚
    """
    # 1. å°è¯•è·å– Keyï¼Œå¦‚æœæ²¡é…æˆ–æ˜¯è¢«æ³¨é‡Šæ‰äº†ï¼Œç›´æ¥è¿”å› True
    encrypt_key = getattr(Config, 'FEISHU_ENCRYPT_KEY', None)
    if not encrypt_key:
        return True 

    # 2. è·å–é£ä¹¦ä¼ æ¥çš„å®‰å…¨å¤´ä¿¡æ¯
    timestamp = request_headers.get("X-Lark-Request-Timestamp")
    nonce = request_headers.get("X-Lark-Request-Nonce")
    signature = request_headers.get("X-Lark-Signature")
    
    if not all([timestamp, nonce, signature]):
        return False

    # 3. æŒ‰ç…§æ ‡å‡† SHA-256 ç®—æ³•æ¯”å¯¹
    try:
        content = (timestamp + nonce + encrypt_key).encode('utf-8') + request_body
        local_sig = hashlib.sha256(content).hexdigest()
        
        if local_sig == signature:
            return True
        else:
            logger.warning(f"ç­¾åä¸åŒ¹é…! è¿œç¨‹:{signature[:8]}... æœ¬åœ°:{local_sig[:8]}...")
            return False
    except Exception as e:
        logger.error(f"ç­¾åæ ¡éªŒå¼‚å¸¸: {e}")
        return False
    # ... åç»­çš„åŠ å¯†æ¯”å¯¹é€»è¾‘ ...

# --- 2. åˆå§‹åŒ–å®¢æˆ·ç«¯ ---
try:
    client = OpenAI(api_key=Config.DEEPSEEK_KEY, base_url="https://api.deepseek.com")
except Exception as e:
    logger.error(f"AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    client = None

# --- 3. åˆå§‹åŒ–å‘é‡åº“ ---
voice_collection = None
bio_collection = None
try:
    if os.path.exists(Config.ASSETS_PATH):
        client_assets = chromadb.PersistentClient(path=Config.ASSETS_PATH)
        voice_collection = client_assets.get_collection(name="cuncun_voice")
    if os.path.exists(Config.MEMORY_PATH):
        client_memory = chromadb.PersistentClient(path=Config.MEMORY_PATH)
        bio_collection = client_memory.get_or_create_collection(name="cuncun_bio")
except Exception as e:
    logger.warning(f"å‘é‡åº“åŠ è½½è­¦å‘Š: {e}")

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

_token_cache = {"token": None, "expires_at": 0}

def get_token():
    """è·å– Token (å¸¦ç¼“å­˜)"""
    current_time = time.time()
    if _token_cache["token"] and current_time < _token_cache["expires_at"] - 300:
        return _token_cache["token"]
    
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
    try:
        r = requests.post(url, json={
            "app_id": Config.FEISHU_APP_ID, 
            "app_secret": Config.FEISHU_APP_SECRET
        }, timeout=10)
        data = r.json()
        token = data.get("tenant_access_token")
        if token:
            _token_cache["token"] = token
            _token_cache["expires_at"] = current_time + data.get("expire", 7200)
            return token
    except Exception as e:
        logger.error(f"Tokenè·å–å¼‚å¸¸: {e}")
    return None

def upload_audio_v2(file_path):
    """åè®®é€†å‘ç‰ˆï¼šä½¿ç”¨ 'file' å­—æ®µå"""
    token = get_token()
    if not token or not os.path.exists(file_path): return None
    
    url = "https://open.feishu.cn/open-apis/im/v1/files"
    headers = {"Authorization": f"Bearer {token}"}
    filename = os.path.basename(file_path)
    
    try:
        with open(file_path, 'rb') as f:
            files = {
                'file_type': (None, 'opus'),
                'file_name': (None, filename),
                'file': (filename, f.read(), 'application/octet-stream')
            }
            r = requests.post(url, headers=headers, files=files, timeout=20)
            res = r.json()
            if res.get("code") == 0:
                logger.info(f"âœ… ä¸Šä¼ æˆåŠŸ Key: {res['data']['file_key']}")
                return res['data']['file_key']
            else:
                logger.error(f"âŒ ä¸Šä¼ å¤±è´¥: {res}")
                return None
    except Exception as e:
        logger.error(f"ä¸Šä¼ å¼‚å¸¸: {e}")
        return None

def send_feishu(receive_id, msg_type, content):
    """é€šç”¨å‘é€å‡½æ•°"""
    token = get_token()
    if not token: return False
    url = "https://open.feishu.cn/open-apis/im/v1/messages?receive_id_type=open_id"
    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
    try:
        r = requests.post(url, headers=headers, json={
            "receive_id": receive_id,
            "msg_type": msg_type,
            "content": json.dumps(content)
        }, timeout=10)
        return r.json().get("code") == 0
    except Exception as e:
        logger.error(f"å‘é€é£ä¹¦æ¶ˆæ¯å¤±è´¥: {e}")
        return False

def get_embedding(text):
    if not Config.SILICONFLOW_API_KEY: return None
    try:
        url = "https://api.siliconflow.cn/v1/embeddings"
        headers = {"Authorization": f"Bearer {Config.SILICONFLOW_API_KEY}", "Content-Type": "application/json"}
        r = requests.post(url, json={"model": "BAAI/bge-large-zh-v1.5", "input": text}, headers=headers, timeout=10)
        return r.json()["data"][0]["embedding"] if r.status_code == 200 else None
    except Exception as e:
        logger.error(f"å‘é‡è·å–å¤±è´¥: {e}")
        return None
        
# --- æœ€ç»ˆä¼˜åŒ–åçš„è¯­éŸ³åŒ¹é…é€»è¾‘ ---
def match_voice_file(text):
    if not voice_collection: 
        return None
    
    # 1. å½»åº•æ¸…æ´—æ–‡æœ¬ï¼šå»æ‰æ‰€æœ‰å½¢å¼çš„åŠ¨ä½œæ ‡ç­¾å’Œæ—ç™½
    # è¦†ç›–ï¼š[ ] , ( ) , ï¼ˆ ï¼‰, ã€ ã€‘
    clean_text = re.sub(r"\[.*?\]|ï¼ˆ.*?ï¼‰|\(.*?\)|ã€.*?ã€‘", "", text).strip()
    
    # 2. åˆ†å¥å¤„ç†ï¼šå¢åŠ å¯¹â€œ...â€å’Œâ€œ..â€è¿™ç§å£è¯­åŒ–çœç•¥å·çš„å¤„ç†
    # è¿™æ ·å¯ä»¥é¿å…æŠŠâ€œå“ˆï¼Ÿä½ é‚£äº›è®¾è®¡ç¨¿...â€ è¿™ç§é•¿å¥ç›´æ¥é€å»åŒ¹é…
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿï¼?ï¼Œ,ï¼›; \n]|[.]{2,}', clean_text)
    # è¿‡æ»¤æ‰ç©ºæ ¼å’Œé•¿åº¦å°äº 2 çš„ç‰‡æ®µï¼ˆå¦‚â€œå“ˆâ€ã€â€œå—¯â€ï¼‰ï¼Œé™¤éåº“é‡Œæœ‰å¾ˆå¤šè¿™ç§çŸ­éŸ³
    sentences = [s.strip() for s in sentences if len(s.strip()) > 1] 
    
    if not sentences:
        logger.warning(f"âš ï¸ æ¸…æ´—åæ— æœ‰æ•ˆåˆ†å¥: {text[:20]}...")
        return None

    logger.info(f"ğŸ” å¼€å¯åˆ†å¥æ£€ç´¢ï¼Œç‰‡æ®µæ€»æ•°: {len(sentences)}")

    try:
        for sentence in sentences:
            # è¿™é‡Œçš„ get_embedding å»ºè®®ä½¿ç”¨ä½ ç°æœ‰çš„ 768 ç»´æ¨¡å‹
            vec = get_embedding(sentence)
            if not vec: continue
            
            # 3. æœç´¢æœ€åŒ¹é…çš„ 1 æ¡ç»“æœ
            res = voice_collection.query(query_embeddings=[vec], n_results=1)
            
            if res["distances"] and len(res["distances"][0]) > 0:
                distance = res["distances"][0][0]
                
                # 4. é˜ˆå€¼è®¾å®šä¸º 0.48
                # æ—¥å¿—æ˜¾ç¤ºä½ çš„æˆåŠŸæ¡ˆä¾‹åœ¨ 0.41 é™„è¿‘ï¼Œ0.4 èƒ½å¤§å¹…æå‡â€œè®¾è®¡ç¨¿â€è¿™ç±»å¥å­çš„åŒ¹é…å¯èƒ½
                if distance < 0.48: 
                    matched_filename = res["metadatas"][0][0]["filename"]
                    logger.info(f"âœ¨ åŒ¹é…å‘½ä¸­! [{sentence}] -> {matched_filename} (è·ç¦»: {distance:.4f})")
                    return os.path.join(Config.VOICE_LIB, matched_filename)
                else:
                    logger.info(f"â­ï¸ ç‰‡æ®µ [{sentence}] æœ€æ¥è¿‘è·ç¦»ä¸º {distance:.4f}ï¼Œæœªè¾¾æ ‡")
                
        logger.warning("âŒ æ‰€æœ‰åˆ†å¥å‡åŒ¹é…å¤±è´¥")
        
    except Exception as e:
        logger.error(f"è¯­éŸ³åŒ¹é…è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
        
    return None

def call_ai(system_prompt, user_text, history=[]):
    if not client: return "AI æœªè¿æ¥"
    try:
        start_time = time.time()
        res = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "system", "content": system_prompt}] + history + [{"role": "user", "content": user_text}],
            temperature=0.9,
            max_tokens=2048,
            presence_penalty=0.6,
            frequency_penalty=0.5
        )
        duration = time.time() - start_time
        logger.info(f"AI å“åº”æˆåŠŸ", extra={"duration": round(duration, 2)}) #
        return res.choices[0].message.content
    except Exception as e:
        logger.error(f"AI é”™è¯¯: {e}")
        return "æˆ‘æœ‰ç‚¹ç´¯äº†ï¼Œç¨ç­‰ä¸€ä¸‹ã€‚"

# --- è¿ç»´åŠŸèƒ½ ---

def check_health():
    """å¥åº·æ£€æŸ¥"""
    health_data = {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "components": {
            "ai": client is not None,
            "voice_db": voice_collection is not None,
            "feishu_api": get_token() is not None
        }
    }
    logger.info("æ‰§è¡Œå¥åº·æ£€æŸ¥", extra={"health_data": health_data})
    return health_data

def backup_database_task():
    """æ•°æ®åº“å¤‡ä»½"""
    try:
        if not os.path.exists(Config.BACKUP_DIR):
            os.makedirs(Config.BACKUP_DIR, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = os.path.join(Config.BACKUP_DIR, f"backup_{timestamp}.db")
        
        shutil.copy2(Config.DB_PATH, backup_path)
        logger.info(f"ğŸ’¾ æ•°æ®åº“å¤‡ä»½æˆåŠŸ", extra={"backup_file": os.path.basename(backup_path)})
        
        # æ¸…ç†æ—§å¤‡ä»½ (ä¿ç•™7å¤©)
        retention = time.time() - (7 * 86400)
        for f in os.listdir(Config.BACKUP_DIR):
            fp = os.path.join(Config.BACKUP_DIR, f)
            if os.path.getmtime(fp) < retention:
                os.remove(fp)
                logger.info(f"æ¸…ç†è¿‡æœŸå¤‡ä»½", extra={"removed_file": f})
    except Exception as e:
        logger.error(f"å¤‡ä»½å¤±è´¥: {e}")

class AESCipher:
    def __init__(self, key):
        self.key = hashlib.sha256(key.encode('utf-8')).digest()

    def decrypt(self, encrypt_text):
        encrypt_bytes = base64.b64decode(encrypt_text)
        iv = encrypt_bytes[:16]
        cipher = AES.new(self.key, AES.MODE_CBC, iv)
        decrypted_bytes = cipher.decrypt(encrypt_bytes[16:])
        # ç§»é™¤ PKCS7 å¡«å……
        padding_len = decrypted_bytes[-1]
        decrypted_json = decrypted_bytes[:-padding_len].decode('utf-8')
        return json.loads(decrypted_json)